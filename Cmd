docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.7.0
docker run -d -p 4566:4566 -p 4571:4571 -v /caminho/do/diretório/no/host:/caminho/do/diretório/no/container localstack/localstack
Tabela solicitacao_credito: essa tabela tem cerca de 40 milhões de registros com cerca de 1 KB por registro, o que resulta em um armazenamento de 40 GB. Essa tabela usa o modo de capacidade provisionada, com 50 WCUs e 50 RCUs. Essa tabela tem uma GSI chamada codigo_cliente-codigo_produto, que é acessada cerca de 60 mil vezes por dia e tem o mesmo tamanho e capacidade da tabela principal. Essa tabela também tem o streaming ativado para enviar dados ao ElasticSearch, o que gera cerca de 50 mil solicitações por dia. O custo mensal estimado para essa tabela é de $ 64,82.
Tabela regras_roteamento: essa tabela tem cerca de 50 registros com cerca de 100 KB por registro, o que resulta em um armazenamento de 5 MB. Essa tabela usa o modo de capacidade on-demand, com 100 solicitações de leitura por dia. Essa tabela não tem nenhuma GSI nem streaming. O custo mensal estimado para essa tabela é de $ 0,01.

as seguintes estratégias para otimizar o seu cluster elasticsearch na AWS:

Use o recurso de pausa e retomada do Amazon Elasticsearch Service, que permite pausar o seu cluster quando ele não estiver em uso, e retomá-lo quando precisar. Isso pode reduzir significativamente o custo do seu cluster, pois você só paga pelo armazenamento EBS enquanto o cluster estiver pausado. Você pode configurar o recurso de pausa e retomada usando o Console do Amazon Elasticsearch Service, a CLI da AWS ou o SDK da AWS1.
Use o recurso de Ultrawarm do Amazon Elasticsearch Service, que permite mover os seus dados menos acessados para um armazenamento mais barato, mas ainda disponível para consulta. Isso pode reduzir o custo do seu armazenamento EBS, pois você pode usar volumes menores para os seus nós de dados. Você pode configurar o recurso de Ultrawarm usando o Console do Amazon Elasticsearch Service, a CLI da AWS ou o SDK da AWS2.
Use instâncias reservadas para o seu cluster elasticsearch, que oferecem um desconto de até 52% em relação às instâncias sob demanda, se você se comprometer com um período de 1 ou 3 anos. Isso pode reduzir o custo das suas instâncias EC2, pois você paga uma taxa fixa por hora ou por mês. Você pode comprar instâncias reservadas usando o Console do Amazon Elasticsearch Service ou a CLI da AWS3.
Usando essas estratégias, eu fiz uma estimativa usando a calculadora do Amazon Elasticsearch Service, e obtive os seguintes resultados:

Você precisa de 2 nós de dados do tipo r5.large.elasticsearch, que têm 2 vCPUs, 16 GB de RAM e 64 GB de armazenamento EBS cada um. Você pode usar instâncias reservadas com pagamento mensal por 1 ano, que custam cerca de US$ 0,17 por hora por nó, ou US$ 124,80 por mês por nó.
Você precisa de 1 nó Ultrawarm do tipo r5.large.elasticsearch, que tem 2 vCPUs, 16 GB de RAM e 512 GB de armazenamento S3. Você pode usar instâncias reservadas com pagamento mensal por 1 ano, que custam cerca de US$ 0,06 por hora por nó, ou US$ 43,80 por mês por nó.
Você precisa de 1 zona de disponibilidade, que é a região onde o seu cluster elasticsearch será hospedado. Isso vai custar cerca de US$ 0,02 por hora por zona, ou US$ 14,60 por mês por zona.
Você precisa de 1 domínio elasticsearch, que é o nome que identifica o seu cluster elasticsearch na AWS. Isso não tem custo adicional.
O custo total estimado para o seu cluster elasticsearch na AWS é de cerca de US$ 308,00 por mês. No entanto, se você usar o recurso de pausa e retomada, e pausar o seu cluster por 16 horas por dia, 2 dias por semana, você pode reduzir o custo para cerca de US$ 147,00 por mês, que está dentro do seu orçamento.


# Importando o módulo boto3
import boto3


import shutil

shutil.make_archive("final", "zip", "./lambda")
# Criando um cliente para acessar o serviço DynamoDB
dynamodb = boto3.client(
    "dynamodb", endpoint_url="http://localhost:4566", region_name="us-east-1"
)
# Criando um recurso do tipo aws_lambda_function
lambdafn = boto3.client(
    "lambda", endpoint_url="http://localhost:4566", region_name="us-east-1"
)
iam = boto3.client("iam", endpoint_url="http://localhost:4566", region_name="us-east-1")

try:
    iam.detach_role_policy(
        RoleName="LambdaDynamoDBRole",
        PolicyArn="arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole",
    )
except:
    print("1")

try:
    iam.detach_role_policy(
        RoleName="LambdaDynamoDBRole",
        PolicyArn="arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess",
    )
except:
    print("2")

try:
    iam.delete_role(RoleName="LambdaDynamoDBRole")
except:
    print("3")

try:
    dynamodb.delete_table(TableName="Pedidos")
except:
    print("4")

try:
    lambdafn.delete_function(FunctionName="ProcessDynamoDBRecords")
except Exception as e:
    print("5")

# Criando uma tabela chamada Pedidos
table = dynamodb.create_table(
    # Definindo o nome da tabela
    TableName="Pedidos",
    # Definindo os atributos da tabela
    AttributeDefinitions=[
        {"AttributeName": "codigo_pedido_credito", "AttributeType": "S"},
        {"AttributeName": "chave_ordenacao", "AttributeType": "S"},
        {"AttributeName": "codigo_cliente", "AttributeType": "S"},
        {"AttributeName": "codigo_produto", "AttributeType": "S"},
    ],
    # Definindo a chave primária da tabela
    KeySchema=[
        {
            "AttributeName": "codigo_pedido_credito",
            "KeyType": "HASH",  # Chave de classificação
        },
        {
            "AttributeName": "chave_ordenacao",
            "KeyType": "RANGE",  # Chave de classificação
        },
    ],
    GlobalSecondaryIndexes=[
        {
            "IndexName": "codigo_cliente_codigo_produto_index",
            "KeySchema": [
                {"AttributeName": "codigo_cliente", "KeyType": "HASH"},
                {"AttributeName": "codigo_produto", "KeyType": "RANGE"},
            ],
            "Projection": {
                "ProjectionType": "INCLUDE",
                "NonKeyAttributes": [
                    "codigo_pedido_credito",
                    "data_pedido",
                    "status_pedido",
                ],
            },
            "ProvisionedThroughput": {"ReadCapacityUnits": 5, "WriteCapacityUnits": 5},
        },
    ],
    # Habilitando o streaming da tabela
    StreamSpecification={
        "StreamEnabled": True,
        "StreamViewType": "NEW_AND_OLD_IMAGES",  # Capturando as imagens antes e depois dos itens modificados
    },
    # Definindo o throughput provisionado da tabela
    ProvisionedThroughput={"ReadCapacityUnits": 5, "WriteCapacityUnits": 5},
)


# Criando uma role chamada LambdaDynamoDBRole
role = iam.create_role(
    # Definindo o nome da role
    RoleName="LambdaDynamoDBRole",
    # Definindo a política de confiança da role
    AssumeRolePolicyDocument="""{
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Principal": {
                    "Service": "lambda.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
            }
        ]
    }""",
)

# Anexando a política gerenciada AWSLambdaBasicExecutionRole à role
iam.attach_role_policy(
    # Especificando o nome da role
    RoleName="LambdaDynamoDBRole",
    # Especificando a ARN da política gerenciada
    PolicyArn="arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole",
)

# Anexando a política gerenciada AmazonDynamoDBFullAccess à role
iam.attach_role_policy(
    # Especificando o nome da role
    RoleName="LambdaDynamoDBRole",
    # Especificando a ARN da política gerenciada
    PolicyArn="arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess",
)


# Criando uma função do Lambda chamada ProcessDynamoDBRecords
function = lambdafn.create_function(
    # Definindo o nome da função
    FunctionName="ProcessDynamoDBRecords",
    # Definindo o arquivo zip com o código da função
    Code={"ZipFile": open("final.zip", "rb").read()},
    # Definindo a função handler
    Handler="lambda_streaming_elasticsearch.lambda_handler",
    # Definindo o tempo de execução
    Runtime="python3.9",
    # Definindo a função de execução que dá à função permissão para acessar recursos do AWS
    Role="arn:aws:iam::000000000000:role/LambdaDynamoDBRole",
)

# Criando um recurso do tipo aws_lambda_event_source_mapping
mapping = lambdafn.create_event_source_mapping(
    # Definindo a função lambda que será acionada pelo stream
    FunctionName="ProcessDynamoDBRecords",
    StartingPosition="LATEST",
    # Definindo o stream do dynamo que será a fonte do evento
    EventSourceArn=table["TableDescription"]["LatestStreamArn"],
)


| Possibilidade | Descrição | Prós | Contras |
| --- | --- | --- | --- |
| Verificar se existe algum pedido em aberto nos últimos 90 dias para o conjunto id_cliente e cod_produto na base | Essa solução consiste em usar uma regra única e simples para todas as chamadas, baseada na existência ou não de um pedido em aberto para o mesmo cliente e produto nos últimos 90 dias. | - Mais fácil de implementar e manter <br> - Mais escalável e confiável <br> - Melhor performance | - Menor satisfação do cliente <br> - Não atende às especificidades de cada segmento <br> - Pode gerar conflitos entre as áreas do banco |
| Parametrizar a regra que identifica se é atacado ou varejo, e depois executar a regra específica do segmento para identificar se reutiliza o id que já existe ou cria outro | Essa solução consiste em usar uma regra diferente e complexa para cada tipo de chamada, baseada em um parâmetro que identifica se é atacado ou varejo, e depois em uma regra específica do segmento para reutilizar ou criar um novo id. | - Maior satisfação do cliente <br> - Atende às especificidades de cada segmento <br> - Melhor integração entre as áreas do banco | - Mais difícil de implementar e manter <br> - Menos escalável e confiável <br> - Pior performance |
