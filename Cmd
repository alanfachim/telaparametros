// Importar as classes necessárias
import com.amazonaws.xray.AWSXRay;
import com.amazonaws.xray.proxies.apache.http.HttpClientBuilder;
import com.amazonaws.xray.entities.Subsegment;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.entity.StringEntity;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.util.EntityUtils;
import com.google.gson.Gson;

// Definir a classe adapter
public class PedidoCreditoAdapter {

  // Definir o método post que envia o pedidoCredito para o serviço roteador
  public void post(PedidoCredito pedidoCredito) {
    // Criar um cliente HTTP com o httpbuilder do aws x-ray
    CloseableHttpClient httpClient = HttpClientBuilder.create().build();

    // Criar um objeto Gson para serializar o pedidoCredito em JSON
    Gson gson = new Gson();
    String json = gson.toJson(pedidoCredito);

    // Criar um objeto HttpPost com a URL do serviço roteador
    HttpPost httpPost = new HttpPost("https://servico-roteador.com");

    // Configurar o cabeçalho e o corpo da requisição
    httpPost.setHeader("Content-type", "application/json");
    httpPost.setEntity(new StringEntity(json, "UTF-8"));

    // Criar um subsegmento do X-Ray para rastrear a requisição
    Subsegment subsegment = AWSXRay.beginSubsegment("Post pedidoCredito");

    try {
      // Executar a requisição e obter a resposta
      org.apache.http.HttpResponse response = httpClient.execute(httpPost);

      // Verificar o status da resposta
      int statusCode = response.getStatusLine().getStatusCode();
      if (statusCode >= 200 && statusCode < 300) {
        // Sucesso
        subsegment.putAnnotation("Status", "Success");
      } else {
        // Erro
        subsegment.putAnnotation("Status", "Error");
        subsegment.putAnnotation("Error", response.getStatusLine().getReasonPhrase());
      }

      // Fechar a resposta e o cliente HTTP
      EntityUtils.consume(response.getEntity());
      httpClient.close();

    } catch (Exception e) {
      // Capturar e registrar a exceção
      subsegment.addException(e);
      e.printStackTrace();
    } finally {
      // Finalizar o subsegmento do X-Ray
      AWSXRay.endSubsegment();
    }
  }
}


import { TestBed } from '@angular/core/testing';
import { HttpClientTestingModule, HttpTestingController } from '@angular/common/http/testing';
import { PedidosService, Pedido } from './pedidosService';

describe('PedidosService', () => {
  let service: PedidosService;
  let httpMock: HttpTestingController;

  beforeEach(() => {
    TestBed.configureTestingModule({
      imports: [HttpClientTestingModule],
      providers: [PedidosService]
    });
    service = TestBed.inject(PedidosService);
    httpMock = TestBed.inject(HttpTestingController);
  });

  afterEach(() => {
    httpMock.verify();
  });

  it('should be created', () => {
    expect(service).toBeTruthy();
  });

  it('should get a pedido by id', () => {
    const mockPedido: Pedido = {
      codigo_pedido_credito: 1,
      cnpj: '123456789',
      status_pedido: 'Aprovado',
      segmento_bancario: 'Banco do Brasil',
      codigo_canal_solicitacao: 2,
      descricao_canal_solicitacao: 'Online',
      valor_pedido: 1000,
      unidade_monetaria: 'Real',
      nome_grupo: 'Grupo A',
      data_pedido: '2023-12-09',
      prazo: 12,
      unidade_prazo: 'Meses',
      codigo_identificacao_origem: 3,
      parecer_origem_pedido: 'OK'
    };
    service.base_url =""
    const id = 1;
    service.getPedidos(id).subscribe((pedido: any) => {
      expect(pedido).toEqual(mockPedido);
    });
    const req = httpMock.expectOne(`${service.base_url}/pedidos/${id}`);
    expect(req.request.method).toBe('GET');
    req.flush(mockPedido);
  });

  // You can write similar tests for other methods using httpMock
});



import unittest
from lambd import lambda_handler, unmarshal_dynamodb_json
import boto3
import moto

class TestLambdaFunction(unittest.TestCase):

    def setUp(self):
        # Criar um evento de exemplo com um registro do DynamoDB
        self.event = {
            "Records": [
                {
                    "eventID": "1",
                    "eventName": "INSERT",
                    "eventVersion": "1.0",
                    "eventSource": "aws:dynamodb",
                    "awsRegion": "us-east-1",
                    "dynamodb": {
                        "ApproximateCreationDateTime": 1626271620,
                        "Keys": {
                            "codigo_pedido_credito": {
                                "S": "12345678-1234-1234-1234-123456789012"
                            },
                            "chave_ordenacao": {
                                "S": "#PEDIDO"
                            }
                        },
                        "NewImage": {
                            "codigo_pedido_credito": {
                                "S": "12345678-1234-1234-1234-123456789012"
                            },
                            "chave_ordenacao": {
                                "S": "#PEDIDO"
                            },
                            "codigoCliente": {
                                "S": "12345678901"
                            },
                            "produto": {
                                "S": "Crédito Pessoal"
                            },
                            "valorPedido": {
                                "N": "1000"
                            },
                            "dataPedido": {
                                "S": "2021-07-14"
                            },
                            "status": {
                                "S": "Aprovado"
                            }
                        },
                        "SequenceNumber": "111",
                        "SizeBytes": 26,
                        "StreamViewType": "NEW_AND_OLD_IMAGES"
                    },
                    "eventSourceARN": "arn:aws:dynamodb:us-east-1:123456789012:table/PedidoCredito/stream/2021-07-14T19:51:37.457"
                }
            ]
        }

        # Criar um contexto de exemplo com um limite de tempo de 10 segundos
        self.context = {
            "function_name": "lambda_function",
            "function_version": "$LATEST",
            "invoked_function_arn": "arn:aws:lambda:us-east-1:123456789012:function:lambda_function",
            "memory_limit_in_mb": "128",
            "aws_request_id": "52fdfc07-2182-154f-163f-5f0f9a621d72",
            "log_group_name": "/aws/lambda/lambda_function",
            "log_stream_name": "2021/07/14/[$LATEST]58419525dade4d17a495dceeeed44708",
            "deadline_ms": 1626271620000 + 10000 # 10 segundos depois do tempo de criação do evento
        }

    @moto.mock_dynamodb2
    @moto.mock_secretsmanager
    @moto.mock_opensearch
    def test_lambda_handler(self):
        # Criar um mock do OpenSearch com um índice pedidocredito
        os_client = boto3.client("opensearch")
        os_client.create_domain(DomainName="pedidocredito")
        os_client.create_index(IndexName="pedidocredito")

        # Chamar a função lambda com o evento e o contexto de exemplo
        result = lambda_handler(self.event, self.context)
        # Verificar se o resultado é None, pois a função não retorna nada
        self.assertIsNone(result)
        # Verificar se o documento foi inserido no índice pedidocredito
        doc = os_client.get(index="pedidocredito", id="12345678-1234-1234-1234-123456789012")
        self.assertEqual(doc["_source"], {
            "codigo_pedido_credito": "12345678-1234-1234-1234-123456789012",
            "chave_ordenacao": "#PEDIDO",
            "codigoCliente": "12345678901",
            "produto": "Crédito Pessoal",
            "valorPedido": 1000,
            "dataPedido": "2021-07-14",
            "status": "Aprovado"
        })

    def test_unmarshal_dynamodb_json(self):
        # Obter o item do evento de exemplo
        item = self.event['Records'][0]['dynamodb']['NewImage']
        # Chamar a função unmarshal_dynamodb_json com o item
        doc_body = unmarshal_dynamodb_json(item)
        # Verificar se o doc_body é um dicionário Python
        self.assertIsInstance(doc_body, dict)
        # Verificar se o doc_body contém os campos esperados
        self.assertEqual(doc_body['codigo_pedido_credito'], '12345678-1234-1234-1234-123456789012')
        self.assertEqual(doc_body['chave_ordenacao'], '#PEDIDO')
        self.assertEqual(doc_body['codigoCliente'], '12345678901')
        self.assertEqual(doc_body['produto'], 'Crédito Pessoal')
        self.assertEqual(doc_body['valorPedido'], 1000)
        self.assertEqual(doc_body['dataPedido'], '2021-07-14')
        self.assertEqual(doc_body['status'], 'Aprovado')

if __name__ == '__main__':
    unittest.main()




// Crie uma classe que implementa a interface HttpRequestInterceptor public class ResponseInterceptor implements HttpRequestInterceptor {

@Override public void process(HttpRequest request, HttpContext context) throws HttpException, IOException {
// Obtenha o objeto HttpResponse do contexto 
HttpResponse response = (HttpResponse) context.getAttribute(HttpCoreContext.HTTP_RESPONSE);
// Imprima o status code da resposta System.out.println("Status code: " + response.getStatusLine().getStatusCode()); 
} }

docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.7.0
docker run -d -p 4566:4566 -p 4571:4571 -v /caminho/do/diretório/no/host:/caminho/do/diretório/no/container localstack/localstack


// Adicione as seguintes linhas para imprimir o erro
      for (DynamoDBMapper.FailedBatch failedBatch : failedBatches) {
        Exception e = failedBatch.getException(); // Obtém a exceção do lote
        String errorMessage = e.getMessage(); // Obtém a mensagem de erro da exceção
        System.out.println(errorMessage); // Imprime a mensagem de erro na saída padrão
        // Ou use um logger para gravar a mensagem de erro em um arquivo de log
        // logger.error(errorMessage);
      }
      throw new Exception("dfsdf");

Tabela solicitacao_credito: essa tabela tem cerca de 40 milhões de registros com cerca de 1 KB por registro, o que resulta em um armazenamento de 40 GB. Essa tabela usa o modo de capacidade provisionada, com 50 WCUs e 50 RCUs. Essa tabela tem uma GSI chamada codigo_cliente-codigo_produto, que é acessada cerca de 60 mil vezes por dia e tem o mesmo tamanho e capacidade da tabela principal. Essa tabela também tem o streaming ativado para enviar dados ao ElasticSearch, o que gera cerca de 50 mil solicitações por dia. O custo mensal estimado para essa tabela é de $ 64,82.
Tabela regras_roteamento: essa tabela tem cerca de 50 registros com cerca de 100 KB por registro, o que resulta em um armazenamento de 5 MB. Essa tabela usa o modo de capacidade on-demand, com 100 solicitações de leitura por dia. Essa tabela não tem nenhuma GSI nem streaming. O custo mensal estimado para essa tabela é de $ 0,01.

as seguintes estratégias para otimizar o seu cluster elasticsearch na AWS:

Use o recurso de pausa e retomada do Amazon Elasticsearch Service, que permite pausar o seu cluster quando ele não estiver em uso, e retomá-lo quando precisar. Isso pode reduzir significativamente o custo do seu cluster, pois você só paga pelo armazenamento EBS enquanto o cluster estiver pausado. Você pode configurar o recurso de pausa e retomada usando o Console do Amazon Elasticsearch Service, a CLI da AWS ou o SDK da AWS1.
Use o recurso de Ultrawarm do Amazon Elasticsearch Service, que permite mover os seus dados menos acessados para um armazenamento mais barato, mas ainda disponível para consulta. Isso pode reduzir o custo do seu armazenamento EBS, pois você pode usar volumes menores para os seus nós de dados. Você pode configurar o recurso de Ultrawarm usando o Console do Amazon Elasticsearch Service, a CLI da AWS ou o SDK da AWS2.
Use instâncias reservadas para o seu cluster elasticsearch, que oferecem um desconto de até 52% em relação às instâncias sob demanda, se você se comprometer com um período de 1 ou 3 anos. Isso pode reduzir o custo das suas instâncias EC2, pois você paga uma taxa fixa por hora ou por mês. Você pode comprar instâncias reservadas usando o Console do Amazon Elasticsearch Service ou a CLI da AWS3.
Usando essas estratégias, eu fiz uma estimativa usando a calculadora do Amazon Elasticsearch Service, e obtive os seguintes resultados:

Você precisa de 2 nós de dados do tipo r5.large.elasticsearch, que têm 2 vCPUs, 16 GB de RAM e 64 GB de armazenamento EBS cada um. Você pode usar instâncias reservadas com pagamento mensal por 1 ano, que custam cerca de US$ 0,17 por hora por nó, ou US$ 124,80 por mês por nó.
Você precisa de 1 nó Ultrawarm do tipo r5.large.elasticsearch, que tem 2 vCPUs, 16 GB de RAM e 512 GB de armazenamento S3. Você pode usar instâncias reservadas com pagamento mensal por 1 ano, que custam cerca de US$ 0,06 por hora por nó, ou US$ 43,80 por mês por nó.
Você precisa de 1 zona de disponibilidade, que é a região onde o seu cluster elasticsearch será hospedado. Isso vai custar cerca de US$ 0,02 por hora por zona, ou US$ 14,60 por mês por zona.
Você precisa de 1 domínio elasticsearch, que é o nome que identifica o seu cluster elasticsearch na AWS. Isso não tem custo adicional.
O custo total estimado para o seu cluster elasticsearch na AWS é de cerca de US$ 308,00 por mês. No entanto, se você usar o recurso de pausa e retomada, e pausar o seu cluster por 16 horas por dia, 2 dias por semana, você pode reduzir o custo para cerca de US$ 147,00 por mês, que está dentro do seu orçamento.


# Importando o módulo boto3
import boto3


import shutil

shutil.make_archive("final", "zip", "./lambda")
# Criando um cliente para acessar o serviço DynamoDB
dynamodb = boto3.client(
    "dynamodb", endpoint_url="http://localhost:4566", region_name="us-east-1"
)
# Criando um recurso do tipo aws_lambda_function
lambdafn = boto3.client(
    "lambda", endpoint_url="http://localhost:4566", region_name="us-east-1"
)
iam = boto3.client("iam", endpoint_url="http://localhost:4566", region_name="us-east-1")

try:
    iam.detach_role_policy(
        RoleName="LambdaDynamoDBRole",
        PolicyArn="arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole",
    )
except:
    print("1")

try:
    iam.detach_role_policy(
        RoleName="LambdaDynamoDBRole",
        PolicyArn="arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess",
    )
except:
    print("2")

try:
    iam.delete_role(RoleName="LambdaDynamoDBRole")
except:
    print("3")

try:
    dynamodb.delete_table(TableName="Pedidos")
except:
    print("4")

try:
    lambdafn.delete_function(FunctionName="ProcessDynamoDBRecords")
except Exception as e:
    print("5")

# Criando uma tabela chamada Pedidos
table = dynamodb.create_table(
    # Definindo o nome da tabela
    TableName="Pedidos",
    # Definindo os atributos da tabela
    AttributeDefinitions=[
        {"AttributeName": "codigo_pedido_credito", "AttributeType": "S"},
        {"AttributeName": "chave_ordenacao", "AttributeType": "S"},
        {"AttributeName": "codigo_cliente", "AttributeType": "S"},
        {"AttributeName": "codigo_produto", "AttributeType": "S"},
    ],
    # Definindo a chave primária da tabela
    KeySchema=[
        {
            "AttributeName": "codigo_pedido_credito",
            "KeyType": "HASH",  # Chave de classificação
        },
        {
            "AttributeName": "chave_ordenacao",
            "KeyType": "RANGE",  # Chave de classificação
        },
    ],
    GlobalSecondaryIndexes=[
        {
            "IndexName": "codigo_cliente_codigo_produto_index",
            "KeySchema": [
                {"AttributeName": "codigo_cliente", "KeyType": "HASH"},
                {"AttributeName": "codigo_produto", "KeyType": "RANGE"},
            ],
            "Projection": {
                "ProjectionType": "INCLUDE",
                "NonKeyAttributes": [
                    "codigo_pedido_credito",
                    "data_pedido",
                    "status_pedido",
                ],
            },
            "ProvisionedThroughput": {"ReadCapacityUnits": 5, "WriteCapacityUnits": 5},
        },
    ],
    # Habilitando o streaming da tabela
    StreamSpecification={
        "StreamEnabled": True,
        "StreamViewType": "NEW_AND_OLD_IMAGES",  # Capturando as imagens antes e depois dos itens modificados
    },
    # Definindo o throughput provisionado da tabela
    ProvisionedThroughput={"ReadCapacityUnits": 5, "WriteCapacityUnits": 5},
)


# Criando uma role chamada LambdaDynamoDBRole
role = iam.create_role(
    # Definindo o nome da role
    RoleName="LambdaDynamoDBRole",
    # Definindo a política de confiança da role
    AssumeRolePolicyDocument="""{
        "Version": "2012-10-17",
        "Statement": [
            {
                "Effect": "Allow",
                "Principal": {
                    "Service": "lambda.amazonaws.com"
                },
                "Action": "sts:AssumeRole"
            }
        ]
    }""",
)

# Anexando a política gerenciada AWSLambdaBasicExecutionRole à role
iam.attach_role_policy(
    # Especificando o nome da role
    RoleName="LambdaDynamoDBRole",
    # Especificando a ARN da política gerenciada
    PolicyArn="arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole",
)

# Anexando a política gerenciada AmazonDynamoDBFullAccess à role
iam.attach_role_policy(
    # Especificando o nome da role
    RoleName="LambdaDynamoDBRole",
    # Especificando a ARN da política gerenciada
    PolicyArn="arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess",
)


# Criando uma função do Lambda chamada ProcessDynamoDBRecords
function = lambdafn.create_function(
    # Definindo o nome da função
    FunctionName="ProcessDynamoDBRecords",
    # Definindo o arquivo zip com o código da função
    Code={"ZipFile": open("final.zip", "rb").read()},
    # Definindo a função handler
    Handler="lambda_streaming_elasticsearch.lambda_handler",
    # Definindo o tempo de execução
    Runtime="python3.9",
    # Definindo a função de execução que dá à função permissão para acessar recursos do AWS
    Role="arn:aws:iam::000000000000:role/LambdaDynamoDBRole",
)

# Criando um recurso do tipo aws_lambda_event_source_mapping
mapping = lambdafn.create_event_source_mapping(
    # Definindo a função lambda que será acionada pelo stream
    FunctionName="ProcessDynamoDBRecords",
    StartingPosition="LATEST",
    # Definindo o stream do dynamo que será a fonte do evento
    EventSourceArn=table["TableDescription"]["LatestStreamArn"],
)


| Possibilidade | Descrição | Prós | Contras |
| --- | --- | --- | --- |
| Verificar se existe algum pedido em aberto nos últimos 90 dias para o conjunto id_cliente e cod_produto na base | Essa solução consiste em usar uma regra única e simples para todas as chamadas, baseada na existência ou não de um pedido em aberto para o mesmo cliente e produto nos últimos 90 dias. | - Mais fácil de implementar e manter <br> - Mais escalável e confiável <br> - Melhor performance | - Menor satisfação do cliente <br> - Não atende às especificidades de cada segmento <br> - Pode gerar conflitos entre as áreas do banco |
| Parametrizar a regra que identifica se é atacado ou varejo, e depois executar a regra específica do segmento para identificar se reutiliza o id que já existe ou cria outro | Essa solução consiste em usar uma regra diferente e complexa para cada tipo de chamada, baseada em um parâmetro que identifica se é atacado ou varejo, e depois em uma regra específica do segmento para reutilizar ou criar um novo id. | - Maior satisfação do cliente <br> - Atende às especificidades de cada segmento <br> - Melhor integração entre as áreas do banco | - Mais difícil de implementar e manter <br> - Menos escalável e confiável <br> - Pior performance |



<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
                             http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>com.svcsolicitarcredito</groupId>
  <artifactId>servico-spring-boot</artifactId>
  <version>1.0.0</version>
  <packaging>jar</packaging>

  <!-- Definir o parent do Spring Boot Starter -->
  <parent>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-parent</artifactId>
    <version>3.0.7</version>
    <relativePath/>
  </parent>

  <!-- Definir as propriedades do projeto -->
  <properties>
    <java.version>17</java.version>
    <aws-java-sdk.version>1.12.49</aws-java-sdk.version>
    <spring-data-dynamodb.version>5.2.7</spring-data-dynamodb.version>
  </properties>

  <!-- Definir as dependências do projeto -->
  <dependencies>
    <!-- Dependência do Spring Boot Starter Web -->
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- Dependência do AWS SDK for Java -->
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-bom</artifactId>
      <version>${aws-java-sdk.version}</version>
      <type>pom</type>
      <scope>import</scope>
    </dependency>

    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-dynamodb</artifactId>
      <version>1.11.970</version>
    </dependency>
    <dependency>
      <groupId>io.github.boostchicken</groupId>
      <artifactId>spring-data-dynamodb</artifactId>
      <version>5.2.5</version>
    </dependency>
    <dependency>
      <groupId>org.elasticsearch.client</groupId>
      <artifactId>elasticsearch-rest-high-level-client</artifactId>
      <version>7.13.0</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/javax.persistence/javax.persistence-api -->
    <dependency>
      <groupId>javax.persistence</groupId>
      <artifactId>javax.persistence-api</artifactId>
      <version>2.2</version>
    </dependency>

    <!-- https://mvnrepository.com/artifact/org.mapstruct/mapstruct -->
    <dependency>
      <groupId>org.mapstruct</groupId>
      <artifactId>mapstruct</artifactId>
      <version>1.5.5.Final</version>
    </dependency>



    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-data-elasticsearch</artifactId>
      <exclusions>
        <exclusion>
          <groupId>org.springframework.boot</groupId>
          <artifactId>spring-boot-starter-logging</artifactId>
        </exclusion>
      </exclusions>
    </dependency>

    <!-- Dependência do Spring Boot Starter Test -->
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-test</artifactId>
      <scope>test</scope>
    </dependency>

    <dependency>
      <groupId>org.projectlombok</groupId>
      <artifactId>lombok</artifactId>
      <version>1.18.20</version>
      <scope>provided</scope>
    </dependency>
  </dependencies>


  <!-- Definir o plugin do Spring Boot Maven -->
  <build>
    <plugins>
      <plugin>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-maven-plugin</artifactId>
      </plugin>
    <plugin>
      <groupId>org.apache.maven.plugins</groupId>
      <artifactId>maven-compiler-plugin</artifactId>
      <version>3.8.1</version>
      <configuration>
        <source>${java.version}</source>
        <target>${java.version}</target>
        <annotationProcessorPaths>
          <path>
            <groupId>org.mapstruct</groupId>
            <artifactId>mapstruct-processor</artifactId>
            <version>1.5.5.Final</version>
          </path>
        </annotationProcessorPaths>
      </configuration>
    </plugin>
  </plugins>
  </build>

</project>


package com.svcsolicitarcredito.infrastructure.config;

import org.apache.http.HttpHost;
import org.apache.http.auth.AuthScope;
import org.apache.http.auth.UsernamePasswordCredentials;
import org.apache.http.client.CredentialsProvider;
import org.apache.http.impl.client.BasicCredentialsProvider;
import org.apache.http.impl.nio.client.HttpAsyncClientBuilder;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestClientBuilder;
import org.elasticsearch.client.RestHighLevelClient;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.data.elasticsearch.client.ClientConfiguration;
import org.springframework.data.elasticsearch.client.elc.ElasticsearchConfiguration;
import org.springframework.data.elasticsearch.core.ElasticsearchOperations;
import org.springframework.data.elasticsearch.repository.config.EnableElasticsearchRepositories;

import javax.net.ssl.KeyManager;
import javax.net.ssl.KeyManagerFactory;
import javax.net.ssl.SSLContext;
import java.io.IOException;
import java.io.InputStream;
import java.security.KeyStore;
import java.security.KeyStoreException;
import java.security.NoSuchAlgorithmException;
import java.security.UnrecoverableKeyException;
import java.security.cert.CertificateException;

// Classe para configurar o ElasticSearch
@Configuration
@EnableElasticsearchRepositories(basePackages = "com.svcsolicitarcredito.infrastructure.repository.es")
public class ElasticSearchConfig {

  private static final String CERT_FILE = "client.p12";
  private static final String CERT_PASSWORD = "topsecret";
  private static final String USER_NAME = "user";
  private static final String USER_PASS = "password";
  @Value("${elasticsearch.host}")
  private String elasticsearchHost;

  @Value("${elasticsearch.port}")
  private int elasticsearchPort;

  @Bean
  public RestHighLevelClient client () {
    final CredentialsProvider credentialsProvider = new BasicCredentialsProvider();
    credentialsProvider.setCredentials (AuthScope.ANY,
            new UsernamePasswordCredentials("myusername", "mypassword"));

    RestClientBuilder builder = RestClient.builder (new HttpHost(
                    "localhost", 9200, "https"))
            .setHttpClientConfigCallback (new RestClientBuilder.HttpClientConfigCallback () {
              @Override
              public HttpAsyncClientBuilder customizeHttpClient (HttpAsyncClientBuilder httpClientBuilder) {
                return httpClientBuilder.setDefaultCredentialsProvider (credentialsProvider);
              }
            });
    return new RestHighLevelClient(builder);
  }

}


package com.svcsolicitarcredito.infrastructure.adapter;

import com.svcsolicitarcredito.domain.entity.ListaPedidoCredito;
import com.svcsolicitarcredito.domain.entity.SearchCriteria;
import com.svcsolicitarcredito.domain.port.out.SearchPedidoPort;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.elasticsearch.core.ElasticsearchOperations;
import org.springframework.data.elasticsearch.core.SearchHits;
import org.springframework.data.elasticsearch.core.query.Criteria;
import org.springframework.data.elasticsearch.core.query.CriteriaQuery;
import org.springframework.stereotype.Component;

@Component
public class ElasticSearchPedidoAdapter implements SearchPedidoPort {
    // Adiciona a anotação @Autowired para injetar o objeto elasticsearchOperations
    @Autowired
    private ElasticsearchOperations elasticsearchOperations;


    @Override
    public SearchHits<ListaPedidoCredito> searchPedidos (SearchCriteria searchCriteria){
        // Cria um objeto de critério inicial
        Criteria criteria = new Criteria();
        // Adiciona as condições ao critério, se informadas
        if (searchCriteria.getCodigoCliente() != null) {
            criteria = criteria.and("codigo_cliente").is(searchCriteria.getCodigoCliente());
        }
        if (searchCriteria.getProduto() != null) {
            criteria = criteria.and("produto").is(searchCriteria.getProduto());
        }
        if (searchCriteria.getValorMinimo() != null) {
            criteria = criteria.and("valor").greaterThanEqual(searchCriteria.getValorMinimo());
        }
        if (searchCriteria.getValorMaximo() != null) {
            criteria = criteria.and("valor").lessThanEqual(searchCriteria.getValorMaximo());
        }
        if (searchCriteria.getDataInicio() != null) {
            criteria = criteria.and("data_pedido").greaterThanEqual(searchCriteria.getDataInicio());
        }
        if (searchCriteria.getDataFim() != null) {
            criteria = criteria.and("data_pedido").lessThanEqual(searchCriteria.getDataFim());
        }
        if (searchCriteria.getStatus() != null) {
            criteria = criteria.and("status").is(searchCriteria.getStatus());
        }
        // Cria um objeto de consulta com o critério
        var query = new CriteriaQuery(criteria);
        // Executa a consulta usando o cliente do Spring Data Elasticsearch e obtém os resultados
        return elasticsearchOperations.search(query, ListaPedidoCredito.class);
    }



}
